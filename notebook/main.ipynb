{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d271166-d29a-4978-9d70-8a171144fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import musdb\n",
    "mus = musdb.DB(download=True)\n",
    "print(\"Tracks:\", len(mus.tracks))\n",
    "print(\"Root:\", mus.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a45a8b-295b-4d45-a318-db6e48e4bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import musdb\n",
    "import soundfile as sf\n",
    "\n",
    "# Paths\n",
    "musdb_root = \"/MUSDB18/MUSDB18-7\"\n",
    "output_root = \"/MUSDB18/MUSDB18-train\"\n",
    "\n",
    "# Create folders for stems\n",
    "stems = [\"vocals\", \"drums\", \"bass\", \"others\"]\n",
    "for stem in stems:\n",
    "    os.makedirs(os.path.join(output_root, stem), exist_ok=True)\n",
    "\n",
    "# Load training dataset\n",
    "mus_train = musdb.DB(root=musdb_root, subsets=\"train\")\n",
    "\n",
    "# Iterate over all tracks\n",
    "for track in mus_train.tracks:\n",
    "    print(f\"Processing track: {track.name}\")\n",
    "    # Save each stem individually\n",
    "    for stem_name in [\"vocals\", \"drums\", \"bass\", \"accompaniment\"]:\n",
    "        audio = track.targets[stem_name].audio  # shape: (samples, channels)\n",
    "        \n",
    "        # Map 'accompaniment' to 'others'\n",
    "        out_stem_name = \"others\" if stem_name == \"accompaniment\" else stem_name\n",
    "        \n",
    "        # File path to save\n",
    "        out_file = os.path.join(output_root, out_stem_name, f\"{track.name}_{stem_name}.wav\")\n",
    "        \n",
    "        # Save as wav\n",
    "        sf.write(out_file, audio, track.rate)\n",
    "\n",
    "print(\"All tracks separated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd32560-9e0b-4686-a79b-ac4f9426b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Audio, display\n",
    "import soundfile as sf\n",
    "\n",
    "SR = 44100\n",
    "idx = 6  # Change this to play a different sample\n",
    "\n",
    "# Paths to each stem folder\n",
    "bass_path   = \"/MUSDB18-train/bass\"\n",
    "drums_path  = \"/MUSDB18-train/drums\"\n",
    "vocals_path = \"/MUSDB18-train/vocals\"\n",
    "others_path = \"/MUSDB18-train/others\"\n",
    "\n",
    "# Get sorted lists of files\n",
    "bass_files   = sorted([f for f in os.listdir(bass_path) if f.endswith(\".wav\")])\n",
    "drums_files  = sorted([f for f in os.listdir(drums_path) if f.endswith(\".wav\")])\n",
    "vocals_files = sorted([f for f in os.listdir(vocals_path) if f.endswith(\".wav\")])\n",
    "others_files = sorted([f for f in os.listdir(others_path) if f.endswith(\".wav\")])\n",
    "\n",
    "# Load and play bass\n",
    "bass_file = os.path.join(bass_path, bass_files[idx])\n",
    "bass_audio, sr = sf.read(bass_file)\n",
    "if bass_audio.ndim > 1:\n",
    "    bass_audio = bass_audio.mean(axis=1)\n",
    "print(\"Bass:\", bass_files[idx])\n",
    "display(Audio(bass_audio, rate=sr))\n",
    "\n",
    "# Load and play drums\n",
    "drums_file = os.path.join(drums_path, drums_files[idx])\n",
    "drums_audio, sr = sf.read(drums_file)\n",
    "if drums_audio.ndim > 1:\n",
    "    drums_audio = drums_audio.mean(axis=1)\n",
    "print(\"Drums:\", drums_files[idx])\n",
    "display(Audio(drums_audio, rate=sr))\n",
    "\n",
    "# Load and play vocals\n",
    "vocals_file = os.path.join(vocals_path, vocals_files[idx])\n",
    "vocals_audio, sr = sf.read(vocals_file)\n",
    "if vocals_audio.ndim > 1:\n",
    "    vocals_audio = vocals_audio.mean(axis=1)\n",
    "print(\"Vocals:\", vocals_files[idx])\n",
    "display(Audio(vocals_audio, rate=sr))\n",
    "\n",
    "# Load and play others\n",
    "others_file = os.path.join(others_path, others_files[idx])\n",
    "others_audio, sr = sf.read(others_file)\n",
    "if others_audio.ndim > 1:\n",
    "    others_audio = others_audio.mean(axis=1)\n",
    "print(\"Others:\", others_files[idx])\n",
    "display(Audio(others_audio, rate=sr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c75bb9-4618-4096-a502-ce44fb8f5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import musdb\n",
    "import soundfile as sf\n",
    "\n",
    "# Paths\n",
    "musdb_root = \"/MUSDB18/MUSDB18-7\"\n",
    "output_root = \"/MUSDB18/MUSDB18-test\"\n",
    "\n",
    "# Create folders for stems\n",
    "stems = [\"vocals\", \"drums\", \"bass\", \"others\"]\n",
    "for stem in stems:\n",
    "    os.makedirs(os.path.join(output_root, stem), exist_ok=True)\n",
    "\n",
    "# Load training dataset\n",
    "mus_test = musdb.DB(root=musdb_root, subsets=\"test\")\n",
    "\n",
    "# Iterate over all tracks\n",
    "for track in mus_test.tracks:\n",
    "    print(f\"Processing track: {track.name}\")\n",
    "    # Save each stem individually\n",
    "    for stem_name in [\"vocals\", \"drums\", \"bass\", \"accompaniment\"]:\n",
    "        audio = track.targets[stem_name].audio  # shape: (samples, channels)\n",
    "        \n",
    "        # Map 'accompaniment' to 'others'\n",
    "        out_stem_name = \"others\" if stem_name == \"accompaniment\" else stem_name\n",
    "        \n",
    "        # File path to save\n",
    "        out_file = os.path.join(output_root, out_stem_name, f\"{track.name}_{stem_name}.wav\")\n",
    "        \n",
    "        # Save as wav\n",
    "        sf.write(out_file, audio, track.rate)\n",
    "\n",
    "print(\"All tracks separated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca007d7-2306-457e-9167-af5a2bd67dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# Base path where original stems are stored\n",
    "base_path = \"/MUSDB18-train/\"\n",
    "\n",
    "# Original stem folders\n",
    "stems = [\"bass\", \"vocals\", \"drums\", \"others\"]\n",
    "\n",
    "# Output path for synthetic mixtures\n",
    "output_base = os.path.join(base_path, \"synthetic_mixtures\")\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# Get sorted list of files for each stem\n",
    "stem_files = {}\n",
    "for stem in stems:\n",
    "    folder = os.path.join(base_path, stem)\n",
    "    files = sorted([f for f in os.listdir(folder) if f.endswith(\".wav\")])\n",
    "    stem_files[stem] = files\n",
    "\n",
    "# Function to load audio as mono\n",
    "def load_audio(path):\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = audio.mean(axis=1)\n",
    "    return audio, sr\n",
    "\n",
    "# Function to save audio\n",
    "def save_audio(audio, sr, out_path):\n",
    "    sf.write(out_path, audio, sr)\n",
    "\n",
    "# Generate all 2-stem and 3-stem combinations\n",
    "for r in [2, 3]:\n",
    "    combos = list(itertools.combinations(stems, r))\n",
    "    for combo in combos:\n",
    "        combo_name = \"_\".join(combo)\n",
    "        out_folder = os.path.join(output_base, combo_name)\n",
    "        os.makedirs(out_folder, exist_ok=True)\n",
    "        \n",
    "        # Number of files (assuming all stems have same filenames)\n",
    "        num_files = len(stem_files[combo[0]])\n",
    "        \n",
    "        for idx in range(num_files):\n",
    "            audios = []\n",
    "            sr = None\n",
    "            \n",
    "            # Load each stem in the combination\n",
    "            for stem in combo:\n",
    "                file_path = os.path.join(base_path, stem, stem_files[stem][idx])\n",
    "                audio, sr = load_audio(file_path)\n",
    "                audios.append(audio)\n",
    "            \n",
    "            # Check lengths and truncate to minimum length\n",
    "            lengths = [a.shape[0] for a in audios]\n",
    "            min_len = min(lengths)\n",
    "            if len(set(lengths)) > 1:\n",
    "                print(f\"Truncating track {stem_files[combo[0]][idx]} for combination {combo_name} \"\n",
    "                      f\"from lengths {lengths} to minimum length {min_len}\")\n",
    "            audios = [a[:min_len] for a in audios]\n",
    "            \n",
    "            # Sum to create mixture\n",
    "            mixture = np.sum(audios, axis=0)\n",
    "            \n",
    "            # Normalize to avoid clipping\n",
    "            mixture = mixture / np.max(np.abs(mixture))\n",
    "            \n",
    "            # Save synthetic mixture\n",
    "            out_file = os.path.join(out_folder, stem_files[combo[0]][idx])  # use first stem's filename\n",
    "            save_audio(mixture, sr, out_file)\n",
    "\n",
    "print(\"All synthetic 2-stem and 3-stem mixtures generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e7961-c73b-45cc-9e3c-ae96e4d2e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Audio, display\n",
    "import soundfile as sf\n",
    "\n",
    "SR = 44100\n",
    "idx = 5  # Change this to play a different sample\n",
    "\n",
    "# Base folder containing all synthetic mixture combinations\n",
    "synthetic_base = \"/MUSDB18-train/\"\n",
    "\n",
    "# Paths to each combination folder (explicitly)\n",
    "bass_vocals_path       = os.path.join(synthetic_base, \"bass_vocals\")\n",
    "bass_drums_path        = os.path.join(synthetic_base, \"bass_drums\")\n",
    "bass_others_path       = os.path.join(synthetic_base, \"bass_others\")\n",
    "vocals_drums_path      = os.path.join(synthetic_base, \"vocals_drums\")\n",
    "vocals_others_path     = os.path.join(synthetic_base, \"vocals_others\")\n",
    "drums_others_path      = os.path.join(synthetic_base, \"drums_others\")\n",
    "bass_vocals_drums_path = os.path.join(synthetic_base, \"bass_vocals_drums\")\n",
    "bass_vocals_others_path= os.path.join(synthetic_base, \"bass_vocals_others\")\n",
    "bass_drums_others_path = os.path.join(synthetic_base, \"bass_drums_others\")\n",
    "vocals_drums_others_path= os.path.join(synthetic_base, \"vocals_drums_others\")\n",
    "\n",
    "# Function to load audio as mono\n",
    "def load_mono_audio(path):\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = audio.mean(axis=1)\n",
    "    return audio, sr\n",
    "\n",
    "# Get sorted file lists\n",
    "bass_vocals_files        = sorted([f for f in os.listdir(bass_vocals_path) if f.endswith(\".wav\")])\n",
    "bass_drums_files         = sorted([f for f in os.listdir(bass_drums_path) if f.endswith(\".wav\")])\n",
    "bass_others_files        = sorted([f for f in os.listdir(bass_others_path) if f.endswith(\".wav\")])\n",
    "vocals_drums_files       = sorted([f for f in os.listdir(vocals_drums_path) if f.endswith(\".wav\")])\n",
    "vocals_others_files      = sorted([f for f in os.listdir(vocals_others_path) if f.endswith(\".wav\")])\n",
    "drums_others_files       = sorted([f for f in os.listdir(drums_others_path) if f.endswith(\".wav\")])\n",
    "bass_vocals_drums_files  = sorted([f for f in os.listdir(bass_vocals_drums_path) if f.endswith(\".wav\")])\n",
    "bass_vocals_others_files = sorted([f for f in os.listdir(bass_vocals_others_path) if f.endswith(\".wav\")])\n",
    "bass_drums_others_files  = sorted([f for f in os.listdir(bass_drums_others_path) if f.endswith(\".wav\")])\n",
    "vocals_drums_others_files= sorted([f for f in os.listdir(vocals_drums_others_path) if f.endswith(\".wav\")])\n",
    "\n",
    "# Play bass_vocals\n",
    "file_path = os.path.join(bass_vocals_path, bass_vocals_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Bass + Vocals:\", bass_vocals_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play bass_drums\n",
    "file_path = os.path.join(bass_drums_path, bass_drums_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Bass + Drums:\", bass_drums_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play bass_others\n",
    "file_path = os.path.join(bass_others_path, bass_others_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Bass + Others:\", bass_others_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play vocals_drums\n",
    "file_path = os.path.join(vocals_drums_path, vocals_drums_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Vocals + Drums:\", vocals_drums_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play vocals_others\n",
    "file_path = os.path.join(vocals_others_path, vocals_others_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Vocals + Others:\", vocals_others_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play drums_others\n",
    "file_path = os.path.join(drums_others_path, drums_others_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Drums + Others:\", drums_others_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play bass_vocals_drums\n",
    "file_path = os.path.join(bass_vocals_drums_path, bass_vocals_drums_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Bass + Vocals + Drums:\", bass_vocals_drums_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play bass_vocals_others\n",
    "file_path = os.path.join(bass_vocals_others_path, bass_vocals_others_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Bass + Vocals + Others:\", bass_vocals_others_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play bass_drums_others\n",
    "file_path = os.path.join(bass_drums_others_path, bass_drums_others_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Bass + Drums + Others:\", bass_drums_others_files[idx])\n",
    "display(Audio(audio, rate=sr))\n",
    "\n",
    "# Play vocals_drums_others\n",
    "file_path = os.path.join(vocals_drums_others_path, vocals_drums_others_files[idx])\n",
    "audio, sr = load_mono_audio(file_path)\n",
    "print(\"Vocals + Drums + Others:\", vocals_drums_others_files[idx])\n",
    "display(Audio(audio, rate=sr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb91a1-d29f-4d1f-9252-d170948b2400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Path to one audio file from your dataset\n",
    "audio_path = \"/MUSDB18-train/bass/A Classic Education - NightOwl_bass.wav\"\n",
    "\n",
    "# Load with original sampling rate (do NOT resample)\n",
    "wav, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "print(\"Sampling Rate =\", sr)\n",
    "print(\"Number of samples =\", len(wav))\n",
    "print(\"Duration (sec) =\", len(wav) / sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688564b7-5138-4157-bd6e-926900b338d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pywt\n",
    "import librosa\n",
    "\n",
    "# -----------------------------\n",
    "# PARAMETERS\n",
    "# -----------------------------\n",
    "STEMS = [\"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 4      # batch size can be increased after testing memory\n",
    "EPOCHS = 150\n",
    "LEARNING_RATE = 1e-3\n",
    "DWT_LEVELS = 5      # downsample 5 times\n",
    "MAX_LEN = 9376      # length after 5-level DWT of ~300k samples\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# -----------------------------\n",
    "# DATASET\n",
    "# -----------------------------\n",
    "def get_file_label_list(root_dir):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "\n",
    "    # traverse folders for multi-labels\n",
    "    for sub in os.listdir(root_dir):\n",
    "        sub_path = os.path.join(root_dir, sub)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "\n",
    "        stems_in_folder = sub.split(\"_\")\n",
    "        lab = np.zeros(len(STEMS), dtype=np.float32)\n",
    "        for i, s in enumerate(STEMS):\n",
    "            if s in stems_in_folder:\n",
    "                lab[i] = 1.0\n",
    "\n",
    "        # get all wav files in this folder\n",
    "        wav_files = glob.glob(os.path.join(sub_path, \"*.wav\"))\n",
    "        for w in wav_files:\n",
    "            file_paths.append(w)\n",
    "            labels.append(lab.copy())\n",
    "\n",
    "    return file_paths, labels\n",
    "\n",
    "class WaveletDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, max_len=MAX_LEN, dwt_levels=DWT_LEVELS):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "        self.dwt_levels = dwt_levels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def dwt_downsample(self, x):\n",
    "        # Apply multi-level DWT downsampling\n",
    "        for _ in range(self.dwt_levels):\n",
    "            x, _ = pywt.dwt(x, 'haar')\n",
    "        return x\n",
    "\n",
    "    def pad_or_trim(self, x):\n",
    "        if len(x) > self.max_len:\n",
    "            return x[:self.max_len]\n",
    "        elif len(x) < self.max_len:\n",
    "            return np.pad(x, (0, self.max_len - len(x)))\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # load waveform\n",
    "        wav, sr = librosa.load(path, sr=None)\n",
    "        wav = self.dwt_downsample(wav)\n",
    "        wav = self.pad_or_trim(wav)\n",
    "\n",
    "        # return as tensor\n",
    "        x = torch.tensor(wav, dtype=torch.float32).unsqueeze(0)  # shape: (1, T)\n",
    "        y = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL\n",
    "# -----------------------------\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        self.pool = nn.MaxPool1d(2)  # reduce temporal dimension by 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)  # halve time dimension\n",
    "        return out\n",
    "\n",
    "class WaveletCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Conv1d(in_channels, 8, kernel_size=7, padding=3)\n",
    "        self.bn0 = nn.BatchNorm1d(8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer1 = ResBlock1D(8, 16)\n",
    "        self.layer2 = ResBlock1D(16, 32)\n",
    "        self.layer3 = ResBlock1D(32, 64)\n",
    "        self.layer4 = ResBlock1D(64, 128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.bn0(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.global_pool(out).squeeze(-1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# -----------------------------\n",
    "# TRAINING FUNCTIONS\n",
    "# -----------------------------\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            all_preds.append(torch.sigmoid(logits).cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return total_loss / len(loader.dataset), all_preds, all_labels\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN TRAINING\n",
    "# -----------------------------\n",
    "def main_training(root_dir):\n",
    "    # build file lists\n",
    "    file_paths, labels = get_file_label_list(root_dir)\n",
    "\n",
    "    # split 90/10 train/val\n",
    "    n = len(file_paths)\n",
    "    idxs = np.arange(n)\n",
    "    np.random.shuffle(idxs)\n",
    "    split = int(n*0.9)\n",
    "    train_idx, val_idx = idxs[:split], idxs[split:]\n",
    "    train_files = [file_paths[i] for i in train_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_files = [file_paths[i] for i in val_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    # datasets & loaders\n",
    "    train_ds = WaveletDataset(train_files, train_labels)\n",
    "    val_ds = WaveletDataset(val_files, val_labels)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # model, optimizer, loss\n",
    "    model = WaveletCNN().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        val_loss, _, _ = validate(model, val_loader, criterion, DEVICE)\n",
    "        print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f}\")\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_wavelet_cnn.pth\")\n",
    "            print(\"Saved best model.\")\n",
    "    np.save(\"train_losses.npy\", np.array(train_losses))\n",
    "    np.save(\"val_losses.npy\", np.array(val_losses))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_training(\"/MUSDB18-train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29f68d-8b5e-415e-b3d3-e830fa1db185",
   "metadata": {},
   "source": [
    "## Testing Phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e86b92-111c-4a2e-98ce-35d1ee32aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Audio, display\n",
    "import soundfile as sf\n",
    "\n",
    "SR = 44100\n",
    "idx = 5  # Change this to play a different sample\n",
    "\n",
    "# Paths to each stem folder\n",
    "bass_path   = \"/MUSDB18-test/bass\"\n",
    "drums_path  = \"/MUSDB18-test/drums\"\n",
    "vocals_path = \"/MUSDB18-test/vocals\"\n",
    "others_path = \"/MUSDB18-test/others\"\n",
    "\n",
    "# Get sorted lists of files\n",
    "bass_files   = sorted([f for f in os.listdir(bass_path) if f.endswith(\".wav\")])\n",
    "drums_files  = sorted([f for f in os.listdir(drums_path) if f.endswith(\".wav\")])\n",
    "vocals_files = sorted([f for f in os.listdir(vocals_path) if f.endswith(\".wav\")])\n",
    "others_files = sorted([f for f in os.listdir(others_path) if f.endswith(\".wav\")])\n",
    "\n",
    "# Load and play bass\n",
    "bass_file = os.path.join(bass_path, bass_files[idx])\n",
    "bass_audio, sr = sf.read(bass_file)\n",
    "if bass_audio.ndim > 1:\n",
    "    bass_audio = bass_audio.mean(axis=1)\n",
    "print(\"Bass:\", bass_files[idx])\n",
    "display(Audio(bass_audio, rate=sr))\n",
    "\n",
    "# Load and play drums\n",
    "drums_file = os.path.join(drums_path, drums_files[idx])\n",
    "drums_audio, sr = sf.read(drums_file)\n",
    "if drums_audio.ndim > 1:\n",
    "    drums_audio = drums_audio.mean(axis=1)\n",
    "print(\"Drums:\", drums_files[idx])\n",
    "display(Audio(drums_audio, rate=sr))\n",
    "\n",
    "# Load and play vocals\n",
    "vocals_file = os.path.join(vocals_path, vocals_files[idx])\n",
    "vocals_audio, sr = sf.read(vocals_file)\n",
    "if vocals_audio.ndim > 1:\n",
    "    vocals_audio = vocals_audio.mean(axis=1)\n",
    "print(\"Vocals:\", vocals_files[idx])\n",
    "display(Audio(vocals_audio, rate=sr))\n",
    "\n",
    "# Load and play others\n",
    "others_file = os.path.join(others_path, others_files[idx])\n",
    "others_audio, sr = sf.read(others_file)\n",
    "if others_audio.ndim > 1:\n",
    "    others_audio = others_audio.mean(axis=1)\n",
    "print(\"Others:\", others_files[idx])\n",
    "display(Audio(others_audio, rate=sr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84441081-3c85-4075-8577-93594b9c38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# Base path where original stems are stored\n",
    "base_path = \"/MUSDB18-test/\"\n",
    "\n",
    "# Original stem folders\n",
    "stems = [\"bass\", \"vocals\", \"drums\", \"others\"]\n",
    "\n",
    "# Output path for synthetic mixtures\n",
    "output_base = os.path.join(base_path, \"synthetic_mixtures\")\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# Get sorted list of files for each stem\n",
    "stem_files = {}\n",
    "for stem in stems:\n",
    "    folder = os.path.join(base_path, stem)\n",
    "    files = sorted([f for f in os.listdir(folder) if f.endswith(\".wav\")])\n",
    "    stem_files[stem] = files\n",
    "\n",
    "# Function to load audio as mono\n",
    "def load_audio(path):\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = audio.mean(axis=1)\n",
    "    return audio, sr\n",
    "\n",
    "# Function to save audio\n",
    "def save_audio(audio, sr, out_path):\n",
    "    sf.write(out_path, audio, sr)\n",
    "\n",
    "# Generate all 2-stem and 3-stem combinations\n",
    "for r in [2, 3]:\n",
    "    combos = list(itertools.combinations(stems, r))\n",
    "    for combo in combos:\n",
    "        combo_name = \"_\".join(combo)\n",
    "        out_folder = os.path.join(output_base, combo_name)\n",
    "        os.makedirs(out_folder, exist_ok=True)\n",
    "        \n",
    "        # Number of files (assuming all stems have same filenames)\n",
    "        num_files = len(stem_files[combo[0]])\n",
    "        \n",
    "        for idx in range(num_files):\n",
    "            audios = []\n",
    "            sr = None\n",
    "            \n",
    "            # Load each stem in the combination\n",
    "            for stem in combo:\n",
    "                file_path = os.path.join(base_path, stem, stem_files[stem][idx])\n",
    "                audio, sr = load_audio(file_path)\n",
    "                audios.append(audio)\n",
    "            \n",
    "            # Check lengths and truncate to minimum length\n",
    "            lengths = [a.shape[0] for a in audios]\n",
    "            min_len = min(lengths)\n",
    "            if len(set(lengths)) > 1:\n",
    "                print(f\"Truncating track {stem_files[combo[0]][idx]} for combination {combo_name} \"\n",
    "                      f\"from lengths {lengths} to minimum length {min_len}\")\n",
    "            audios = [a[:min_len] for a in audios]\n",
    "            \n",
    "            # Sum to create mixture\n",
    "            mixture = np.sum(audios, axis=0)\n",
    "            \n",
    "            # Normalize to avoid clipping\n",
    "            mixture = mixture / np.max(np.abs(mixture))\n",
    "            \n",
    "            # Save synthetic mixture\n",
    "            out_file = os.path.join(out_folder, stem_files[combo[0]][idx])  # use first stem's filename\n",
    "            save_audio(mixture, sr, out_file)\n",
    "\n",
    "print(\"All synthetic 2-stem and 3-stem mixtures generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d0d4b-fe90-4661-a2db-914ce0dae6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import pywt\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -----------------------------\n",
    "# PARAMETERS\n",
    "# -----------------------------\n",
    "STEMS = [\"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 1\n",
    "DWT_LEVELS = 5\n",
    "MAX_LEN = 9376  # must match training\n",
    "\n",
    "# -----------------------------\n",
    "# DATASET\n",
    "# -----------------------------\n",
    "def get_file_label_list(root_dir):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for sub in os.listdir(root_dir):\n",
    "        sub_path = os.path.join(root_dir, sub)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "\n",
    "        stems_in_folder = sub.split(\"_\")\n",
    "        lab = np.zeros(len(STEMS), dtype=np.float32)\n",
    "        for i, s in enumerate(STEMS):\n",
    "            if s in stems_in_folder:\n",
    "                lab[i] = 1.0\n",
    "\n",
    "        wav_files = glob.glob(os.path.join(sub_path, \"*.wav\"))\n",
    "        for w in wav_files:\n",
    "            file_paths.append(w)\n",
    "            labels.append(lab.copy())\n",
    "\n",
    "    return file_paths, labels\n",
    "\n",
    "class WaveletDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, max_len=MAX_LEN, dwt_levels=DWT_LEVELS):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "        self.dwt_levels = dwt_levels\n",
    "\n",
    "    def dwt_downsample(self, x):\n",
    "        for _ in range(self.dwt_levels):\n",
    "            x, _ = pywt.dwt(x, 'haar')\n",
    "        return x\n",
    "\n",
    "    def pad_or_trim(self, x):\n",
    "        if len(x) > self.max_len:\n",
    "            return x[:self.max_len]\n",
    "        elif len(x) < self.max_len:\n",
    "            return np.pad(x, (0, self.max_len - len(x)))\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        wav, sr = librosa.load(path, sr=None)\n",
    "        wav = self.dwt_downsample(wav)\n",
    "        wav = self.pad_or_trim(wav)\n",
    "        x = torch.tensor(wav, dtype=torch.float32).unsqueeze(0)\n",
    "        y = torch.tensor(label, dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL\n",
    "# -----------------------------\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        return out\n",
    "\n",
    "class WaveletCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Conv1d(in_channels, 8, kernel_size=7, padding=3)\n",
    "        self.bn0 = nn.BatchNorm1d(8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer1 = ResBlock1D(8, 16)\n",
    "        self.layer2 = ResBlock1D(16, 32)\n",
    "        self.layer3 = ResBlock1D(32, 64)\n",
    "        self.layer4 = ResBlock1D(64, 128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.bn0(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.global_pool(out).squeeze(-1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# -----------------------------\n",
    "# EVALUATION\n",
    "# -----------------------------\n",
    "def evaluate_model(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > threshold).float()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='samples', zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, average='samples', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='samples', zero_division=0)\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN\n",
    "# -----------------------------\n",
    "def main_test(test_root_dir, model_path=\"best_wavelet_cnn.pth\"):\n",
    "    # build test dataset\n",
    "    file_paths, labels = get_file_label_list(test_root_dir)\n",
    "    test_ds = WaveletDataset(file_paths, labels)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # load model\n",
    "    model = WaveletCNN().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "\n",
    "    # evaluate\n",
    "    preds, labels = evaluate_model(model, test_loader, DEVICE)\n",
    "\n",
    "    # optional: print first 5 predictions\n",
    "    print(\"First 5 predictions vs labels:\")\n",
    "    for p, l in zip(preds[:5], labels[:5]):\n",
    "        print(p, l)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_test(\"/MUSDB18-test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212bc2c-1f3f-4139-bcd9-d3d7cd1e7d65",
   "metadata": {},
   "source": [
    "## Same Model Architecture Without Using DWT as Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ccb18-2231-471f-80da-03656d9096cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "\n",
    "# -----------------------------\n",
    "# PARAMETERS\n",
    "# -----------------------------\n",
    "STEMS = [\"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 1       # batch size 1 for variable-length input\n",
    "EPOCHS = 150\n",
    "LEARNING_RATE = 1e-3\n",
    "TARGET_SR = 22050     # downsample to 22 kHz\n",
    "\n",
    "train_losses_withoutDWT = []\n",
    "val_losses_withoutDWT = []\n",
    "\n",
    "# -----------------------------\n",
    "# DATASET\n",
    "# -----------------------------\n",
    "def get_file_label_list(root_dir):\n",
    "    file_paths, labels = [], []\n",
    "    for sub in os.listdir(root_dir):\n",
    "        sub_path = os.path.join(root_dir, sub)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "\n",
    "        stems_in_folder = sub.split(\"_\")\n",
    "        lab = np.zeros(len(STEMS), dtype=np.float32)\n",
    "        for i, s in enumerate(STEMS):\n",
    "            if s in stems_in_folder:\n",
    "                lab[i] = 1.0\n",
    "\n",
    "        wav_files = glob.glob(os.path.join(sub_path, \"*.wav\"))\n",
    "        for w in wav_files:\n",
    "            file_paths.append(w)\n",
    "            labels.append(lab.copy())\n",
    "    return file_paths, labels\n",
    "\n",
    "class RawWaveformDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, target_sr=TARGET_SR):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.target_sr = target_sr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load waveform and downsample to 22 kHz\n",
    "        wav, sr = librosa.load(path, sr=None)\n",
    "        if sr != self.target_sr:\n",
    "            wav = librosa.resample(wav, orig_sr=sr, target_sr=self.target_sr)\n",
    "\n",
    "        x = torch.tensor(wav, dtype=torch.float32).unsqueeze(0)  # shape: (1, T)\n",
    "        y = torch.tensor(label, dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL\n",
    "# -----------------------------\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        self.pool = nn.MaxPool1d(4)  # aggressive pooling to reduce sequence length\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        return out\n",
    "\n",
    "class RawWaveCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Conv1d(in_channels, 8, kernel_size=7, padding=3)\n",
    "        self.bn0 = nn.BatchNorm1d(8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer1 = ResBlock1D(8, 16)\n",
    "        self.layer2 = ResBlock1D(16, 32)\n",
    "        self.layer3 = ResBlock1D(32, 64)\n",
    "        self.layer4 = ResBlock1D(64, 128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # works with variable-length input\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.bn0(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.global_pool(out).squeeze(-1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# -----------------------------\n",
    "# TRAINING FUNCTIONS\n",
    "# -----------------------------\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            all_preds.append(torch.sigmoid(logits).cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return total_loss / len(loader.dataset), all_preds, all_labels\n",
    "\n",
    "# -----------------------------\n",
    "# TRAINING LOOP\n",
    "# -----------------------------\n",
    "def main_training(root_dir):\n",
    "    # Build dataset\n",
    "    file_paths, labels = get_file_label_list(root_dir)\n",
    "    n = len(file_paths)\n",
    "    idxs = np.arange(n)\n",
    "    np.random.shuffle(idxs)\n",
    "    split = int(n*0.9)\n",
    "    train_idx, val_idx = idxs[:split], idxs[split:]\n",
    "    train_files = [file_paths[i] for i in train_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_files = [file_paths[i] for i in val_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    train_ds = RawWaveformDataset(train_files, train_labels, target_sr=TARGET_SR)\n",
    "    val_ds   = RawWaveformDataset(val_files, val_labels, target_sr=TARGET_SR)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Model, optimizer, loss\n",
    "    model = RawWaveCNN().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        val_loss, _, _ = validate(model, val_loader, criterion, DEVICE)\n",
    "        print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_rawwave_cnn.pth\")\n",
    "            print(\"Saved best model.\")\n",
    "\n",
    "        # Save losses\n",
    "        train_losses_withoutDWT.append(train_loss)\n",
    "        val_losses_withoutDWT.append(val_loss)\n",
    "\n",
    "    # Save loss history\n",
    "    np.save(\"train_losses_withoutDWT.npy\", np.array(train_losses_withoutDWT))\n",
    "    np.save(\"val_losses_withoutDWT.npy\", np.array(val_losses_withoutDWT))\n",
    "\n",
    "# -----------------------------\n",
    "# RUN\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main_training(\"/MUSDB18-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc07d87-4094-4e00-aeb3-4368ceac34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# -----------------------------\n",
    "# PARAMETERS\n",
    "# -----------------------------\n",
    "STEMS = [\"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 1       # batch size 1 for variable-length input\n",
    "EPOCHS = 150\n",
    "LEARNING_RATE = 1e-3\n",
    "TARGET_SR = 22050     # downsample to 22 kHz\n",
    "\n",
    "train_losses_withoutDWT = []\n",
    "val_losses_withoutDWT = []\n",
    "\n",
    "# -----------------------------\n",
    "# DATASET\n",
    "# -----------------------------\n",
    "def get_file_label_list(root_dir):\n",
    "    file_paths, labels = [], []\n",
    "    for sub in os.listdir(root_dir):\n",
    "        sub_path = os.path.join(root_dir, sub)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "\n",
    "        stems_in_folder = sub.split(\"_\")\n",
    "        lab = np.zeros(len(STEMS), dtype=np.float32)\n",
    "        for i, s in enumerate(STEMS):\n",
    "            if s in stems_in_folder:\n",
    "                lab[i] = 1.0\n",
    "\n",
    "        wav_files = glob.glob(os.path.join(sub_path, \"*.wav\"))\n",
    "        for w in wav_files:\n",
    "            file_paths.append(w)\n",
    "            labels.append(lab.copy())\n",
    "    return file_paths, labels\n",
    "\n",
    "class RawWaveformDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, target_sr=TARGET_SR):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.target_sr = target_sr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load waveform and downsample to 22 kHz\n",
    "        wav, sr = librosa.load(path, sr=None)\n",
    "        if sr != self.target_sr:\n",
    "            wav = librosa.resample(wav, orig_sr=sr, target_sr=self.target_sr)\n",
    "\n",
    "        x = torch.tensor(wav, dtype=torch.float32).unsqueeze(0)  # shape: (1, T)\n",
    "        y = torch.tensor(label, dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL\n",
    "# -----------------------------\n",
    "class ResBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        self.pool = nn.MaxPool1d(4)  # aggressive pooling to reduce sequence length\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.pool(out)\n",
    "        return out\n",
    "\n",
    "class RawWaveCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Conv1d(in_channels, 8, kernel_size=7, padding=3)\n",
    "        self.bn0 = nn.BatchNorm1d(8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer1 = ResBlock1D(8, 16)\n",
    "        self.layer2 = ResBlock1D(16, 32)\n",
    "        self.layer3 = ResBlock1D(32, 64)\n",
    "        self.layer4 = ResBlock1D(64, 128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # works with variable-length input\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.bn0(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.global_pool(out).squeeze(-1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# -----------------------------\n",
    "# TEST / EVALUATION\n",
    "# -----------------------------\n",
    "def evaluate_model(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > threshold).float()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_labels = torch.cat(all_labels, dim=0).numpy()\n",
    "\n",
    "    # metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds, average='samples', zero_division=0)\n",
    "    rec = recall_score(all_labels, all_preds, average='samples', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='samples', zero_division=0)\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n",
    "    return all_preds, all_labels\n",
    "\n",
    "def main_test(test_root_dir, model_path=\"best_rawwave_cnn.pth\"):\n",
    "    file_paths, labels = get_file_label_list(test_root_dir)\n",
    "    test_ds = RawWaveformDataset(file_paths, labels)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = RawWaveCNN().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "\n",
    "    preds, labels = evaluate_model(model, test_loader, DEVICE)\n",
    "    print(\"First 5 predictions vs labels:\")\n",
    "    for p, l in zip(preds[:5], labels[:5]):\n",
    "        print(p, l)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# RUN\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Test\n",
    "    main_test(\"/MUSDB18-test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393df0f5-85a5-4ea7-bfdf-3bd21d50ce9c",
   "metadata": {},
   "source": [
    "## Evaluating Model With  AWGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a98c00-e25d-4101-a020-08d76d3cdb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_awgn(x, snr_db):\n",
    "    \"\"\"\n",
    "    x: numpy array of audio (float32)\n",
    "    snr_db: target SNR in dB\n",
    "    \"\"\"\n",
    "    # Signal power\n",
    "    sig_power = np.mean(x**2)\n",
    "\n",
    "    # Noise power\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    noise_power = sig_power / snr_linear\n",
    "\n",
    "    # Generate noise\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), x.shape)\n",
    "\n",
    "    return x + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404fe3d-f0c0-40c6-9d48-3a9a12c151d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----------------------------\n",
    "# Add AWGN noise function\n",
    "# ----------------------------\n",
    "def add_awgn(x, snr_db):\n",
    "    sig_power = np.mean(x**2)\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    noise_power = sig_power / snr_linear\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), x.shape)\n",
    "    return x + noise\n",
    "\n",
    "# ----------------------------\n",
    "# Get predictions (WaveRCNN)\n",
    "# ----------------------------\n",
    "def predict_wavercnn(model, audio, sr=44100, max_len=300032):\n",
    "    # pad/trim\n",
    "    if len(audio) < max_len:\n",
    "        audio = np.pad(audio, (0, max_len - len(audio)))\n",
    "    else:\n",
    "        audio = audio[:max_len]\n",
    "\n",
    "    x = torch.tensor(audio, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    x = x.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "    return torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# ----------------------------\n",
    "# Get predictions (DWT-CNN)\n",
    "# ----------------------------\n",
    "def compute_dwt(audio, wavelet, level):\n",
    "    import pywt\n",
    "    coeffs = pywt.wavedec(audio, wavelet=wavelet, level=level)\n",
    "    dwt_vector = np.concatenate([c for c in coeffs], axis=-1)\n",
    "    return dwt_vector\n",
    "\n",
    "def predict_dwtcnn(model, audio, wavelet, level):\n",
    "    dwt_vec = compute_dwt(audio, wavelet, level)\n",
    "    \n",
    "    x = torch.tensor(dwt_vec, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    x = torch.nn.functional.interpolate(x, size=4096)  # adjust to model input size\n",
    "    x = x.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "    return torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# ----------------------------\n",
    "# Noisy evaluation loop\n",
    "# ----------------------------\n",
    "def test_under_noise(wavercnn_model, dwt_model, test_files, test_labels,\n",
    "                     wavelet=\"db4\", level=4):\n",
    "\n",
    "    SNR_LEVELS = [20, 30, 40]\n",
    "    results = {}\n",
    "\n",
    "    for snr in SNR_LEVELS:\n",
    "        y_true = []\n",
    "        y_pred_wave = []\n",
    "        y_pred_dwt = []\n",
    "\n",
    "        for audio_path, label in zip(test_files, test_labels):\n",
    "            audio, sr = librosa.load(audio_path, sr=44100)\n",
    "\n",
    "            noisy_audio = add_awgn(audio, snr)\n",
    "\n",
    "            # WaveRCNN prediction\n",
    "            pred_wave = predict_wavercnn(wavercnn_model, noisy_audio)\n",
    "            y_pred_wave.append(pred_wave)\n",
    "\n",
    "            # DWT-CNN prediction\n",
    "            pred_dwt = predict_dwtcnn(dwt_model, noisy_audio, wavelet, level)\n",
    "            y_pred_dwt.append(pred_dwt)\n",
    "\n",
    "            y_true.append(label)\n",
    "\n",
    "        # compute metrics\n",
    "        acc_w = accuracy_score(y_true, y_pred_wave)\n",
    "        acc_d = accuracy_score(y_true, y_pred_dwt)\n",
    "\n",
    "        p_w, r_w, f_w, _ = precision_recall_fscore_support(y_true, y_pred_wave, average='macro')\n",
    "        p_d, r_d, f_d, _ = precision_recall_fscore_support(y_true, y_pred_dwt, average='macro')\n",
    "\n",
    "        results[snr] = {\n",
    "            \"WaveRCNN\": {\n",
    "                \"Accuracy\": acc_w,\n",
    "                \"Precision\": p_w,\n",
    "                \"Recall\": r_w,\n",
    "                \"F1\": f_w,\n",
    "            },\n",
    "            \"DWT-CNN\": {\n",
    "                \"Accuracy\": acc_d,\n",
    "                \"Precision\": p_d,\n",
    "                \"Recall\": r_d,\n",
    "                \"F1\": f_d,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261848e-1e56-44fa-b3bf-e73130ba3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# ----------------------------\n",
    "# PARAMETERS\n",
    "# ----------------------------\n",
    "STEMS = [\"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LEN = 300032  # waveform length\n",
    "\n",
    "# ----------------------------\n",
    "# Add AWGN noise\n",
    "# ----------------------------\n",
    "def add_awgn(x, snr_db):\n",
    "    sig_power = np.mean(x**2)\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    noise_power = sig_power / snr_linear\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), x.shape)\n",
    "    return x + noise\n",
    "\n",
    "# ----------------------------\n",
    "# DWT helper\n",
    "# ----------------------------\n",
    "def compute_dwt(audio, wavelet, level):\n",
    "    import pywt\n",
    "    coeffs = pywt.wavedec(audio, wavelet=wavelet, level=level)\n",
    "    dwt_vector = np.concatenate([c for c in coeffs], axis=-1)\n",
    "    return dwt_vector\n",
    "\n",
    "# ----------------------------\n",
    "# Predictions\n",
    "# ----------------------------\n",
    "def predict_wavercnn(model, audio, max_len=MAX_LEN):\n",
    "    if len(audio) < max_len:\n",
    "        audio = np.pad(audio, (0, max_len - len(audio)))\n",
    "    else:\n",
    "        audio = audio[:max_len]\n",
    "    x = torch.tensor(audio, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "    return torch.argmax(logits, dim=1).item()\n",
    "\n",
    "def predict_dwtcnn(model, audio, wavelet, level, target_len=4096):\n",
    "    dwt_vec = compute_dwt(audio, wavelet, level)\n",
    "    x = torch.tensor(dwt_vec, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    x = torch.nn.functional.interpolate(x, size=target_len).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "    return torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# ----------------------------\n",
    "# Load test files & labels\n",
    "# ----------------------------\n",
    "def get_file_label_list(root_dir):\n",
    "    file_paths, labels = [], []\n",
    "    for sub in os.listdir(root_dir):\n",
    "        sub_path = os.path.join(root_dir, sub)\n",
    "        if not os.path.isdir(sub_path):\n",
    "            continue\n",
    "        stems_in_folder = sub.split(\"_\")\n",
    "        lab = np.zeros(len(STEMS), dtype=np.float32)\n",
    "        for i, s in enumerate(STEMS):\n",
    "            if s in stems_in_folder:\n",
    "                lab[i] = 1.0\n",
    "        wav_files = librosa.util.find_files(sub_path, ext='wav')\n",
    "        for w in wav_files:\n",
    "            file_paths.append(w)\n",
    "            labels.append(lab.copy())\n",
    "    return file_paths, labels\n",
    "\n",
    "# ----------------------------\n",
    "# Test under noise\n",
    "# ----------------------------\n",
    "def test_under_noise(wavercnn_model, dwt_model, test_files, test_labels,\n",
    "                     wavelet=\"db4\", level=4):\n",
    "\n",
    "    SNR_LEVELS = [0,5,10]\n",
    "    results = {}\n",
    "\n",
    "    for snr in SNR_LEVELS:\n",
    "        y_true, y_pred_wave, y_pred_dwt = [], [], []\n",
    "\n",
    "        for audio_path, label in zip(test_files, test_labels):\n",
    "            audio, sr = librosa.load(audio_path, sr=44100)\n",
    "            noisy_audio = add_awgn(audio, snr)\n",
    "\n",
    "            # WaveRCNN prediction\n",
    "            pred_wave = predict_wavercnn(wavercnn_model, noisy_audio)\n",
    "            y_pred_wave.append(pred_wave)\n",
    "\n",
    "            # DWT-CNN prediction\n",
    "            pred_dwt = predict_dwtcnn(dwt_model, noisy_audio, wavelet, level)\n",
    "            y_pred_dwt.append(pred_dwt)\n",
    "\n",
    "            # Convert one-hot label to integer\n",
    "            if isinstance(label, (np.ndarray, list)):\n",
    "                y_true.append(int(np.argmax(label)))\n",
    "            else:\n",
    "                y_true.append(label)\n",
    "    \n",
    "        # compute metrics\n",
    "        acc_w = accuracy_score(y_true, y_pred_wave)\n",
    "        acc_d = accuracy_score(y_true, y_pred_dwt)\n",
    "\n",
    "        p_w, r_w, f_w, _ = precision_recall_fscore_support(y_true, y_pred_wave, average='macro')\n",
    "        p_d, r_d, f_d, _ = precision_recall_fscore_support(y_true, y_pred_dwt, average='macro')\n",
    "\n",
    "        results[snr] = {\n",
    "            \"WaveRCNN\": {\"Accuracy\": acc_w, \"Precision\": p_w, \"Recall\": r_w, \"F1\": f_w},\n",
    "            \"DWT-CNN\": {\"Accuracy\": acc_d, \"Precision\": p_d, \"Recall\": r_d, \"F1\": f_d}\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN RUN\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    from model_dwtcnn import WaveletCNN  \n",
    "    from model_wavercnn import RawWaveCNN\n",
    "\n",
    "    # Load models\n",
    "    wavercnn_model = RawWaveCNN().to(DEVICE)\n",
    "    wavercnn_model.load_state_dict(torch.load(\"best_rawwave_cnn.pth\", map_location=DEVICE))\n",
    "    wavercnn_model.eval()\n",
    "\n",
    "    dwt_model = WaveletCNN().to(DEVICE)\n",
    "    dwt_model.load_state_dict(torch.load(\"best_wavelet_cnn.pth\", map_location=DEVICE))\n",
    "    dwt_model.eval()\n",
    "\n",
    "    # Load test files\n",
    "    test_files, test_labels = get_file_label_list(\"/MUSDB18-test\")\n",
    "\n",
    "    # Evaluate under noise\n",
    "    results = test_under_noise(wavercnn_model, dwt_model, test_files, test_labels,\n",
    "                               wavelet=\"db4\", level=4)\n",
    "\n",
    "    # Print results\n",
    "    for snr, metrics in results.items():\n",
    "        print(f\"\\n==================== SNR = {snr} dB ====================\")\n",
    "        print(\"---- WaveRCNN ----\")\n",
    "        print(f\"Accuracy : {metrics['WaveRCNN']['Accuracy']:.4f}\")\n",
    "        print(f\"Precision: {metrics['WaveRCNN']['Precision']:.4f}\")\n",
    "        print(f\"Recall   : {metrics['WaveRCNN']['Recall']:.4f}\")\n",
    "        print(f\"F1 Score : {metrics['WaveRCNN']['F1']:.4f}\")\n",
    "\n",
    "        print(\"\\n---- DWT-CNN ----\")\n",
    "        print(f\"Accuracy : {metrics['DWT-CNN']['Accuracy']:.4f}\")\n",
    "        print(f\"Precision: {metrics['DWT-CNN']['Precision']:.4f}\")\n",
    "        print(f\"Recall   : {metrics['DWT-CNN']['Recall']:.4f}\")\n",
    "        print(f\"F1 Score : {metrics['DWT-CNN']['F1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca0647a-9269-4bf6-ba8f-94b7059dc276",
   "metadata": {},
   "source": [
    "## Visualization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1199266-d18a-49f4-a1cd-0a8965acf5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import musdb\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load train dataset\n",
    "mus_train = musdb.DB(root=\"/MUSDB18/MUSDB18-7\", subsets=\"train\")\n",
    "track = mus_train.tracks[0]\n",
    "\n",
    "# Convert to mono\n",
    "mixture = track.audio.mean(axis=1)\n",
    "\n",
    "# Wavelet settings\n",
    "wavelet = 'db4'\n",
    "max_level = 5\n",
    "\n",
    "# Single-level decomposition recursively to get all approximations\n",
    "approxs = []\n",
    "current = mixture.copy()\n",
    "for l in range(max_level, 0, -1):\n",
    "    c = pywt.wavedec(current, wavelet, level=1)\n",
    "    approxs.append(c[0])  # approximation at this level\n",
    "    current = c[0]        # go one level deeper\n",
    "\n",
    "# Full DWT for details\n",
    "coeffs = pywt.wavedec(mixture, wavelet, level=max_level)\n",
    "details = [pywt.waverec([None]+[coeffs[i]] + [None]*(max_level-i), wavelet) for i in range(1, max_level+1)]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Original mixture\n",
    "plt.subplot(max_level*2 + 1, 1, 1)\n",
    "plt.plot(mixture)\n",
    "plt.title(\"Original Mixture\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "# Approximations\n",
    "for i, a in enumerate(approxs):\n",
    "    plt.subplot(max_level*2 + 1, 1, i+2)\n",
    "    plt.plot(a)\n",
    "    plt.title(f\"Approximation Level {max_level-i}\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "\n",
    "# Details\n",
    "for i, d in enumerate(details):\n",
    "    plt.subplot(max_level*2 + 1, 1, max_level+2 + i)\n",
    "    plt.plot(d)\n",
    "    plt.title(f\"Detail Level {i+1}\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the loss arrays\n",
    "train_losses = np.load('train_losses.npy')  # replace with your training loss file if different\n",
    "val_losses = np.load('val_losses.npy')\n",
    "\n",
    "# Check that lengths match\n",
    "epochs = range(1, len(val_losses) + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss for DWT Features')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77746693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the loss arrays\n",
    "train_losses = np.load('train_losses_withoutDWT.npy')  # replace with your training loss file if different\n",
    "val_losses = np.load('val_losses_withoutDWT.npy')\n",
    "\n",
    "# Check that lengths match\n",
    "epochs = range(1, len(val_losses) + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss for RAW Features')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
